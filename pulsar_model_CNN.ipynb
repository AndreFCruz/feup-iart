{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_PATH = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "\n",
    "def load_pulsar_csv(path = DATA_PATH):\n",
    "    csv_path = os.path.join(path, 'HTRU_2.csv')\n",
    "    return np.loadtxt(csv_path, delimiter=',', dtype=np.float32)\n",
    "\n",
    "def load_pulsar_arff(path = DATA_PATH):\n",
    "    arff_path = os.path.join(path, 'HTRU_2.arff')\n",
    "    return arff.loadarff(arff_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pulsars = load_pulsar_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_train_dataset(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(test_ratio * len(data))\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data[train_indices,:], data[test_indices,:]\n",
    "\n",
    "# Use hash of identifier to decide if instance goes into train or test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "import os\n",
    "\n",
    "MODELS_DIR = \"models\"\n",
    "\n",
    "def save_model(model, name, acc=None):\n",
    "    name += str(model.input.shape[1])\n",
    "    for layer in model.layers:\n",
    "        name += \"-\" + str(layer.output.shape[1:])\n",
    "    \n",
    "    name += \"_\" + ((\"%.2f\" % acc) if acc is not None else \"\")\n",
    "    path = os.path.join(MODELS_DIR, name + \".h5\")\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = split_train_dataset(pulsars, 0.2)\n",
    "\n",
    "X_train, Y_train = train_set[:, :-1], train_set[:, -1]\n",
    "X_test, Y_test = test_set[:, :-1], test_set[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Dropout, Flatten, Reshape\n",
    "\n",
    "# Create Model\n",
    "input_dimension = np.size(X_train, axis=1)\n",
    "\n",
    "def create_model_cnn():\n",
    "    inputs = Input(shape=(input_dimension,), dtype='float32')\n",
    "    reshape = Reshape((input_dimension,1))(inputs) # reshape input (?,8) to conv input (?,8,1)\n",
    "    conv_0 = Conv1D(64, kernel_size=6, activation='relu')(reshape)\n",
    "    pool = MaxPooling1D()(conv_0)\n",
    "    flatten = Flatten()(pool)\n",
    "    dropout = Dropout(0.2)(flatten)\n",
    "    output = Dense(1, activation='sigmoid')(dropout)\n",
    "    # Compile model\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14319 samples, validate on 3579 samples\n",
      "Epoch 1/150\n",
      "14319/14319 [==============================] - 3s 242us/step - loss: 0.1570 - acc: 0.9610 - val_loss: 0.0888 - val_acc: 0.9737\n",
      "Epoch 2/150\n",
      "14319/14319 [==============================] - 3s 208us/step - loss: 0.0963 - acc: 0.9736 - val_loss: 0.0882 - val_acc: 0.9743\n",
      "Epoch 3/150\n",
      "14319/14319 [==============================] - 3s 216us/step - loss: 0.0952 - acc: 0.9726 - val_loss: 0.0900 - val_acc: 0.9740\n",
      "Epoch 4/150\n",
      "14319/14319 [==============================] - 3s 216us/step - loss: 0.0896 - acc: 0.9749 - val_loss: 0.0868 - val_acc: 0.9751\n",
      "Epoch 5/150\n",
      "14319/14319 [==============================] - 3s 219us/step - loss: 0.0915 - acc: 0.9744 - val_loss: 0.0944 - val_acc: 0.9743\n",
      "Epoch 6/150\n",
      "14319/14319 [==============================] - 3s 216us/step - loss: 0.0879 - acc: 0.9758 - val_loss: 0.0851 - val_acc: 0.9763\n",
      "Epoch 7/150\n",
      "14319/14319 [==============================] - 3s 235us/step - loss: 0.0896 - acc: 0.9743 - val_loss: 0.0809 - val_acc: 0.9763\n",
      "Epoch 8/150\n",
      "14319/14319 [==============================] - 3s 223us/step - loss: 0.0887 - acc: 0.9750 - val_loss: 0.0846 - val_acc: 0.9760\n",
      "Epoch 9/150\n",
      "14319/14319 [==============================] - 3s 236us/step - loss: 0.0889 - acc: 0.9755 - val_loss: 0.0804 - val_acc: 0.9768\n",
      "Epoch 10/150\n",
      "14319/14319 [==============================] - 3s 220us/step - loss: 0.0873 - acc: 0.9758 - val_loss: 0.0796 - val_acc: 0.9768\n",
      "Epoch 11/150\n",
      "14319/14319 [==============================] - 3s 231us/step - loss: 0.0869 - acc: 0.9758 - val_loss: 0.0834 - val_acc: 0.9763\n",
      "Epoch 12/150\n",
      "14319/14319 [==============================] - 4s 249us/step - loss: 0.0876 - acc: 0.9748 - val_loss: 0.0789 - val_acc: 0.9765\n",
      "Epoch 13/150\n",
      "14319/14319 [==============================] - 3s 222us/step - loss: 0.0871 - acc: 0.9749 - val_loss: 0.0879 - val_acc: 0.9754\n",
      "Epoch 14/150\n",
      "14319/14319 [==============================] - 3s 222us/step - loss: 0.0873 - acc: 0.9761 - val_loss: 0.0810 - val_acc: 0.9768\n",
      "Epoch 15/150\n",
      "14319/14319 [==============================] - 3s 227us/step - loss: 0.0874 - acc: 0.9756 - val_loss: 0.0785 - val_acc: 0.9768\n",
      "Epoch 16/150\n",
      "14319/14319 [==============================] - 4s 248us/step - loss: 0.0854 - acc: 0.9758 - val_loss: 0.0780 - val_acc: 0.9771\n",
      "Epoch 17/150\n",
      "14319/14319 [==============================] - 3s 219us/step - loss: 0.0861 - acc: 0.9753 - val_loss: 0.0801 - val_acc: 0.9771\n",
      "Epoch 18/150\n",
      "14319/14319 [==============================] - 3s 239us/step - loss: 0.0857 - acc: 0.9753 - val_loss: 0.0786 - val_acc: 0.9768\n",
      "Epoch 19/150\n",
      "14319/14319 [==============================] - 4s 266us/step - loss: 0.0843 - acc: 0.9756 - val_loss: 0.0814 - val_acc: 0.9776\n",
      "Epoch 20/150\n",
      "14319/14319 [==============================] - 3s 225us/step - loss: 0.0859 - acc: 0.9763 - val_loss: 0.0781 - val_acc: 0.9771\n",
      "Epoch 21/150\n",
      "14319/14319 [==============================] - 3s 229us/step - loss: 0.0842 - acc: 0.9757 - val_loss: 0.0798 - val_acc: 0.9776\n",
      "Epoch 22/150\n",
      "14319/14319 [==============================] - 3s 226us/step - loss: 0.0846 - acc: 0.9760 - val_loss: 0.0789 - val_acc: 0.9776\n",
      "Epoch 23/150\n",
      "14319/14319 [==============================] - 3s 222us/step - loss: 0.0834 - acc: 0.9763 - val_loss: 0.0836 - val_acc: 0.9765\n",
      "Epoch 24/150\n",
      "14319/14319 [==============================] - 3s 219us/step - loss: 0.0833 - acc: 0.9752 - val_loss: 0.0781 - val_acc: 0.9774\n",
      "Epoch 25/150\n",
      "14319/14319 [==============================] - 4s 252us/step - loss: 0.0829 - acc: 0.9754 - val_loss: 0.0772 - val_acc: 0.9776\n",
      "Epoch 26/150\n",
      "14319/14319 [==============================] - 3s 228us/step - loss: 0.0849 - acc: 0.9765 - val_loss: 0.0795 - val_acc: 0.9757\n",
      "Epoch 27/150\n",
      "14319/14319 [==============================] - 4s 257us/step - loss: 0.0852 - acc: 0.9756 - val_loss: 0.0791 - val_acc: 0.9760\n",
      "Epoch 28/150\n",
      "14319/14319 [==============================] - 4s 260us/step - loss: 0.0845 - acc: 0.9767 - val_loss: 0.0784 - val_acc: 0.9774\n",
      "Epoch 29/150\n",
      "14319/14319 [==============================] - 3s 228us/step - loss: 0.0843 - acc: 0.9756 - val_loss: 0.0775 - val_acc: 0.9776\n",
      "Epoch 30/150\n",
      "14319/14319 [==============================] - 4s 250us/step - loss: 0.0832 - acc: 0.9765 - val_loss: 0.0809 - val_acc: 0.9754\n",
      "Epoch 31/150\n",
      "14319/14319 [==============================] - 3s 219us/step - loss: 0.0845 - acc: 0.9758 - val_loss: 0.0767 - val_acc: 0.9779\n",
      "Epoch 32/150\n",
      "14319/14319 [==============================] - 3s 210us/step - loss: 0.0831 - acc: 0.9756 - val_loss: 0.0845 - val_acc: 0.9774\n",
      "Epoch 33/150\n",
      "14319/14319 [==============================] - 3s 215us/step - loss: 0.0837 - acc: 0.9755 - val_loss: 0.0787 - val_acc: 0.9776\n",
      "Epoch 34/150\n",
      "14319/14319 [==============================] - 4s 292us/step - loss: 0.0848 - acc: 0.9757 - val_loss: 0.0777 - val_acc: 0.9768\n",
      "Epoch 35/150\n",
      "14319/14319 [==============================] - 4s 262us/step - loss: 0.0829 - acc: 0.9762 - val_loss: 0.0790 - val_acc: 0.9776\n",
      "Epoch 36/150\n",
      "14319/14319 [==============================] - 3s 228us/step - loss: 0.0836 - acc: 0.9753 - val_loss: 0.0772 - val_acc: 0.9776\n",
      "Epoch 37/150\n",
      "14319/14319 [==============================] - 3s 218us/step - loss: 0.0819 - acc: 0.9770 - val_loss: 0.0791 - val_acc: 0.9774\n",
      "Epoch 38/150\n",
      "14319/14319 [==============================] - 3s 234us/step - loss: 0.0827 - acc: 0.9760 - val_loss: 0.0769 - val_acc: 0.9757\n",
      "Epoch 39/150\n",
      "14319/14319 [==============================] - 4s 259us/step - loss: 0.0834 - acc: 0.9756 - val_loss: 0.0772 - val_acc: 0.9771\n",
      "Epoch 40/150\n",
      "14319/14319 [==============================] - 3s 230us/step - loss: 0.0821 - acc: 0.9767 - val_loss: 0.0789 - val_acc: 0.9754\n",
      "Epoch 41/150\n",
      "14319/14319 [==============================] - 4s 257us/step - loss: 0.0827 - acc: 0.9758 - val_loss: 0.0780 - val_acc: 0.9793\n",
      "Epoch 42/150\n",
      "14319/14319 [==============================] - 3s 233us/step - loss: 0.0829 - acc: 0.9762 - val_loss: 0.0772 - val_acc: 0.9776\n",
      "Epoch 43/150\n",
      "14319/14319 [==============================] - 3s 221us/step - loss: 0.0841 - acc: 0.9759 - val_loss: 0.0776 - val_acc: 0.9785\n",
      "Epoch 44/150\n",
      "14319/14319 [==============================] - 3s 225us/step - loss: 0.0817 - acc: 0.9767 - val_loss: 0.0790 - val_acc: 0.9763\n",
      "Epoch 45/150\n",
      "14319/14319 [==============================] - 4s 254us/step - loss: 0.0829 - acc: 0.9763 - val_loss: 0.0792 - val_acc: 0.9782\n",
      "Epoch 46/150\n",
      "14319/14319 [==============================] - 4s 270us/step - loss: 0.0824 - acc: 0.9761 - val_loss: 0.0770 - val_acc: 0.9776\n",
      "Epoch 47/150\n",
      "14319/14319 [==============================] - 4s 287us/step - loss: 0.0824 - acc: 0.9766 - val_loss: 0.0753 - val_acc: 0.9774\n",
      "Epoch 48/150\n",
      "14319/14319 [==============================] - 5s 317us/step - loss: 0.0809 - acc: 0.9763 - val_loss: 0.0834 - val_acc: 0.9779\n",
      "Epoch 49/150\n",
      "14319/14319 [==============================] - 4s 260us/step - loss: 0.0828 - acc: 0.9767 - val_loss: 0.0759 - val_acc: 0.9779\n",
      "Epoch 50/150\n",
      "14319/14319 [==============================] - 4s 285us/step - loss: 0.0824 - acc: 0.9764 - val_loss: 0.0804 - val_acc: 0.9779\n",
      "Epoch 51/150\n",
      "14319/14319 [==============================] - 3s 234us/step - loss: 0.0824 - acc: 0.9766 - val_loss: 0.0756 - val_acc: 0.9782\n",
      "Epoch 52/150\n",
      "14319/14319 [==============================] - 3s 220us/step - loss: 0.0815 - acc: 0.9764 - val_loss: 0.0804 - val_acc: 0.9785\n",
      "Epoch 53/150\n",
      "14319/14319 [==============================] - 3s 231us/step - loss: 0.0812 - acc: 0.9767 - val_loss: 0.0767 - val_acc: 0.9779\n",
      "Epoch 54/150\n",
      "14319/14319 [==============================] - 4s 290us/step - loss: 0.0828 - acc: 0.9763 - val_loss: 0.0794 - val_acc: 0.9760\n",
      "Epoch 55/150\n",
      "14319/14319 [==============================] - 4s 275us/step - loss: 0.0823 - acc: 0.9770 - val_loss: 0.0763 - val_acc: 0.9776\n",
      "Epoch 56/150\n",
      "14319/14319 [==============================] - 3s 222us/step - loss: 0.0821 - acc: 0.9770 - val_loss: 0.0746 - val_acc: 0.9776\n",
      "Epoch 57/150\n",
      "14319/14319 [==============================] - 4s 270us/step - loss: 0.0810 - acc: 0.9763 - val_loss: 0.0760 - val_acc: 0.9774\n",
      "Epoch 58/150\n",
      "14319/14319 [==============================] - 5s 327us/step - loss: 0.0808 - acc: 0.9765 - val_loss: 0.0748 - val_acc: 0.9782\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14319/14319 [==============================] - 3s 239us/step - loss: 0.0808 - acc: 0.9764 - val_loss: 0.0745 - val_acc: 0.9768\n",
      "Epoch 60/150\n",
      "14319/14319 [==============================] - 3s 218us/step - loss: 0.0822 - acc: 0.9760 - val_loss: 0.0789 - val_acc: 0.9779\n",
      "Epoch 61/150\n",
      "14319/14319 [==============================] - 3s 228us/step - loss: 0.0827 - acc: 0.9765 - val_loss: 0.0751 - val_acc: 0.9790\n",
      "Epoch 62/150\n",
      "14319/14319 [==============================] - 3s 221us/step - loss: 0.0811 - acc: 0.9768 - val_loss: 0.0774 - val_acc: 0.9765\n",
      "Epoch 63/150\n",
      "14319/14319 [==============================] - 3s 236us/step - loss: 0.0804 - acc: 0.9766 - val_loss: 0.0748 - val_acc: 0.9796\n",
      "Epoch 64/150\n",
      "14319/14319 [==============================] - 3s 232us/step - loss: 0.0799 - acc: 0.9765 - val_loss: 0.0737 - val_acc: 0.9779\n",
      "Epoch 65/150\n",
      "14319/14319 [==============================] - 3s 219us/step - loss: 0.0811 - acc: 0.9757 - val_loss: 0.0733 - val_acc: 0.9779\n",
      "Epoch 66/150\n",
      "14319/14319 [==============================] - 3s 218us/step - loss: 0.0802 - acc: 0.9766 - val_loss: 0.0755 - val_acc: 0.9776\n",
      "Epoch 67/150\n",
      "14319/14319 [==============================] - 3s 226us/step - loss: 0.0812 - acc: 0.9762 - val_loss: 0.0747 - val_acc: 0.9774\n",
      "Epoch 68/150\n",
      "14319/14319 [==============================] - 3s 227us/step - loss: 0.0796 - acc: 0.9768 - val_loss: 0.0749 - val_acc: 0.9771\n",
      "Epoch 69/150\n",
      "14319/14319 [==============================] - 3s 225us/step - loss: 0.0812 - acc: 0.9770 - val_loss: 0.0729 - val_acc: 0.9790\n",
      "Epoch 70/150\n",
      "14319/14319 [==============================] - 3s 228us/step - loss: 0.0808 - acc: 0.9759 - val_loss: 0.0758 - val_acc: 0.9779\n",
      "Epoch 71/150\n",
      "14319/14319 [==============================] - 3s 224us/step - loss: 0.0809 - acc: 0.9762 - val_loss: 0.0743 - val_acc: 0.9785\n",
      "Epoch 72/150\n",
      "14319/14319 [==============================] - 3s 223us/step - loss: 0.0808 - acc: 0.9767 - val_loss: 0.0748 - val_acc: 0.9779\n",
      "Epoch 73/150\n",
      "14319/14319 [==============================] - 3s 223us/step - loss: 0.0798 - acc: 0.9772 - val_loss: 0.0757 - val_acc: 0.9788\n",
      "Epoch 74/150\n",
      "14319/14319 [==============================] - 3s 236us/step - loss: 0.0810 - acc: 0.9761 - val_loss: 0.0764 - val_acc: 0.9763\n",
      "Epoch 75/150\n",
      "14319/14319 [==============================] - 3s 223us/step - loss: 0.0797 - acc: 0.9764 - val_loss: 0.0778 - val_acc: 0.9802\n",
      "Epoch 76/150\n",
      "14319/14319 [==============================] - 3s 222us/step - loss: 0.0801 - acc: 0.9764 - val_loss: 0.0776 - val_acc: 0.9799\n",
      "Epoch 77/150\n",
      "14319/14319 [==============================] - 3s 227us/step - loss: 0.0811 - acc: 0.9767 - val_loss: 0.0745 - val_acc: 0.9793\n",
      "Epoch 78/150\n",
      "14319/14319 [==============================] - 3s 231us/step - loss: 0.0811 - acc: 0.9762 - val_loss: 0.0736 - val_acc: 0.9790\n",
      "Epoch 79/150\n",
      "14319/14319 [==============================] - 3s 226us/step - loss: 0.0809 - acc: 0.9763 - val_loss: 0.0728 - val_acc: 0.9790\n",
      "Epoch 80/150\n",
      "14319/14319 [==============================] - 3s 227us/step - loss: 0.0801 - acc: 0.9766 - val_loss: 0.0727 - val_acc: 0.9788\n",
      "Epoch 81/150\n",
      "14319/14319 [==============================] - 3s 213us/step - loss: 0.0806 - acc: 0.9763 - val_loss: 0.0765 - val_acc: 0.9776\n",
      "Epoch 82/150\n",
      "14319/14319 [==============================] - 3s 227us/step - loss: 0.0787 - acc: 0.9770 - val_loss: 0.0712 - val_acc: 0.9779\n",
      "Epoch 83/150\n",
      "14319/14319 [==============================] - 3s 225us/step - loss: 0.0801 - acc: 0.9762 - val_loss: 0.0751 - val_acc: 0.9788\n",
      "Epoch 84/150\n",
      "14319/14319 [==============================] - 3s 227us/step - loss: 0.0794 - acc: 0.9760 - val_loss: 0.0753 - val_acc: 0.9793\n",
      "Epoch 85/150\n",
      "14319/14319 [==============================] - 3s 221us/step - loss: 0.0794 - acc: 0.9770 - val_loss: 0.0735 - val_acc: 0.9785\n",
      "Epoch 86/150\n",
      "14319/14319 [==============================] - 3s 226us/step - loss: 0.0796 - acc: 0.9767 - val_loss: 0.0724 - val_acc: 0.9796\n",
      "Epoch 87/150\n",
      "14319/14319 [==============================] - 3s 223us/step - loss: 0.0804 - acc: 0.9760 - val_loss: 0.0727 - val_acc: 0.9790\n",
      "Epoch 88/150\n",
      "14319/14319 [==============================] - 3s 238us/step - loss: 0.0803 - acc: 0.9774 - val_loss: 0.0720 - val_acc: 0.9788\n",
      "Epoch 89/150\n",
      "14319/14319 [==============================] - 3s 222us/step - loss: 0.0798 - acc: 0.9772 - val_loss: 0.0727 - val_acc: 0.9776\n",
      "Epoch 90/150\n",
      "14319/14319 [==============================] - 3s 223us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0752 - val_acc: 0.9788\n",
      "Epoch 91/150\n",
      "14319/14319 [==============================] - 3s 228us/step - loss: 0.0797 - acc: 0.9779 - val_loss: 0.0731 - val_acc: 0.9785\n",
      "Epoch 92/150\n",
      "14319/14319 [==============================] - 3s 209us/step - loss: 0.0796 - acc: 0.9767 - val_loss: 0.0727 - val_acc: 0.9788\n",
      "Epoch 93/150\n",
      "14319/14319 [==============================] - 3s 215us/step - loss: 0.0806 - acc: 0.9767 - val_loss: 0.0718 - val_acc: 0.9788\n",
      "Epoch 94/150\n",
      "14319/14319 [==============================] - 3s 216us/step - loss: 0.0798 - acc: 0.9775 - val_loss: 0.0751 - val_acc: 0.9793\n",
      "Epoch 95/150\n",
      "14319/14319 [==============================] - 3s 220us/step - loss: 0.0793 - acc: 0.9770 - val_loss: 0.0709 - val_acc: 0.9785\n",
      "Epoch 96/150\n",
      "14319/14319 [==============================] - 3s 215us/step - loss: 0.0789 - acc: 0.9764 - val_loss: 0.0733 - val_acc: 0.9793\n",
      "Epoch 97/150\n",
      "14319/14319 [==============================] - 3s 221us/step - loss: 0.0779 - acc: 0.9773 - val_loss: 0.0735 - val_acc: 0.9782\n",
      "Epoch 98/150\n",
      "14319/14319 [==============================] - 3s 229us/step - loss: 0.0794 - acc: 0.9762 - val_loss: 0.0736 - val_acc: 0.9788\n",
      "Epoch 99/150\n",
      "14319/14319 [==============================] - 3s 227us/step - loss: 0.0791 - acc: 0.9763 - val_loss: 0.0723 - val_acc: 0.9799\n",
      "Epoch 100/150\n",
      "14319/14319 [==============================] - 3s 226us/step - loss: 0.0805 - acc: 0.9773 - val_loss: 0.0751 - val_acc: 0.9788\n",
      "Epoch 101/150\n",
      "14319/14319 [==============================] - 3s 225us/step - loss: 0.0796 - acc: 0.9767 - val_loss: 0.0778 - val_acc: 0.9782\n",
      "Epoch 102/150\n",
      "14319/14319 [==============================] - 3s 223us/step - loss: 0.0804 - acc: 0.9777 - val_loss: 0.0747 - val_acc: 0.9782\n",
      "Epoch 103/150\n",
      "14319/14319 [==============================] - 3s 223us/step - loss: 0.0804 - acc: 0.9764 - val_loss: 0.0721 - val_acc: 0.9785\n",
      "Epoch 104/150\n",
      "14319/14319 [==============================] - 3s 226us/step - loss: 0.0794 - acc: 0.9770 - val_loss: 0.0737 - val_acc: 0.9788\n",
      "Epoch 105/150\n",
      "14319/14319 [==============================] - 3s 223us/step - loss: 0.0789 - acc: 0.9772 - val_loss: 0.0778 - val_acc: 0.9771\n",
      "Epoch 106/150\n",
      "14319/14319 [==============================] - 3s 223us/step - loss: 0.0793 - acc: 0.9765 - val_loss: 0.0737 - val_acc: 0.9796\n",
      "Epoch 107/150\n",
      "14319/14319 [==============================] - 3s 221us/step - loss: 0.0788 - acc: 0.9773 - val_loss: 0.0791 - val_acc: 0.9776\n",
      "Epoch 108/150\n",
      "14319/14319 [==============================] - 4s 299us/step - loss: 0.0789 - acc: 0.9770 - val_loss: 0.0728 - val_acc: 0.9799\n",
      "Epoch 109/150\n",
      "14319/14319 [==============================] - 5s 327us/step - loss: 0.0788 - acc: 0.9776 - val_loss: 0.0740 - val_acc: 0.9802\n",
      "Epoch 110/150\n",
      "14319/14319 [==============================] - 4s 298us/step - loss: 0.0776 - acc: 0.9765 - val_loss: 0.0744 - val_acc: 0.9785\n",
      "Epoch 111/150\n",
      "14319/14319 [==============================] - 4s 245us/step - loss: 0.0796 - acc: 0.9763 - val_loss: 0.0723 - val_acc: 0.9788\n",
      "Epoch 112/150\n",
      "14319/14319 [==============================] - 3s 243us/step - loss: 0.0771 - acc: 0.9781 - val_loss: 0.0717 - val_acc: 0.9793\n",
      "Epoch 113/150\n",
      "14319/14319 [==============================] - 3s 235us/step - loss: 0.0798 - acc: 0.9773 - val_loss: 0.0760 - val_acc: 0.9788\n",
      "Epoch 114/150\n",
      "14319/14319 [==============================] - 3s 216us/step - loss: 0.0795 - acc: 0.9768 - val_loss: 0.0723 - val_acc: 0.9796\n",
      "Epoch 115/150\n",
      "14319/14319 [==============================] - 3s 219us/step - loss: 0.0797 - acc: 0.9757 - val_loss: 0.0724 - val_acc: 0.9782\n",
      "Epoch 116/150\n",
      "14319/14319 [==============================] - 3s 216us/step - loss: 0.0779 - acc: 0.9768 - val_loss: 0.0742 - val_acc: 0.9790\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14319/14319 [==============================] - 3s 216us/step - loss: 0.0787 - acc: 0.9765 - val_loss: 0.0730 - val_acc: 0.9790\n",
      "Epoch 118/150\n",
      "14319/14319 [==============================] - 3s 218us/step - loss: 0.0806 - acc: 0.9772 - val_loss: 0.0735 - val_acc: 0.9788\n",
      "Epoch 119/150\n",
      "14319/14319 [==============================] - 3s 212us/step - loss: 0.0777 - acc: 0.9770 - val_loss: 0.0729 - val_acc: 0.9788\n",
      "Epoch 120/150\n",
      "14319/14319 [==============================] - 3s 218us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0735 - val_acc: 0.9785\n",
      "Epoch 121/150\n",
      "14319/14319 [==============================] - 3s 213us/step - loss: 0.0796 - acc: 0.9767 - val_loss: 0.0832 - val_acc: 0.9774\n",
      "Epoch 122/150\n",
      "14319/14319 [==============================] - 3s 215us/step - loss: 0.0801 - acc: 0.9756 - val_loss: 0.0722 - val_acc: 0.9796\n",
      "Epoch 123/150\n",
      "14319/14319 [==============================] - 3s 244us/step - loss: 0.0783 - acc: 0.9767 - val_loss: 0.0706 - val_acc: 0.9790\n",
      "Epoch 124/150\n",
      "14319/14319 [==============================] - 3s 219us/step - loss: 0.0797 - acc: 0.9767 - val_loss: 0.0751 - val_acc: 0.9776\n",
      "Epoch 125/150\n",
      "14319/14319 [==============================] - 3s 213us/step - loss: 0.0789 - acc: 0.9777 - val_loss: 0.0719 - val_acc: 0.9788\n",
      "Epoch 126/150\n",
      "14319/14319 [==============================] - 3s 220us/step - loss: 0.0788 - acc: 0.9770 - val_loss: 0.0730 - val_acc: 0.9785\n",
      "Epoch 127/150\n",
      "14319/14319 [==============================] - 3s 217us/step - loss: 0.0789 - acc: 0.9773 - val_loss: 0.0748 - val_acc: 0.9785\n",
      "Epoch 128/150\n",
      "14319/14319 [==============================] - 3s 214us/step - loss: 0.0776 - acc: 0.9774 - val_loss: 0.0729 - val_acc: 0.9788\n",
      "Epoch 129/150\n",
      "14319/14319 [==============================] - 3s 221us/step - loss: 0.0777 - acc: 0.9773 - val_loss: 0.0739 - val_acc: 0.9788\n",
      "Epoch 130/150\n",
      "14319/14319 [==============================] - 3s 216us/step - loss: 0.0793 - acc: 0.9767 - val_loss: 0.0771 - val_acc: 0.9776\n",
      "Epoch 131/150\n",
      "14319/14319 [==============================] - 3s 219us/step - loss: 0.0785 - acc: 0.9774 - val_loss: 0.0730 - val_acc: 0.9788\n",
      "Epoch 132/150\n",
      "14319/14319 [==============================] - 3s 212us/step - loss: 0.0786 - acc: 0.9772 - val_loss: 0.0737 - val_acc: 0.9785\n",
      "Epoch 133/150\n",
      "14319/14319 [==============================] - 3s 236us/step - loss: 0.0783 - acc: 0.9774 - val_loss: 0.0729 - val_acc: 0.9776\n",
      "Epoch 134/150\n",
      "14319/14319 [==============================] - 4s 245us/step - loss: 0.0797 - acc: 0.9763 - val_loss: 0.0745 - val_acc: 0.9793\n",
      "Epoch 135/150\n",
      "14319/14319 [==============================] - 3s 217us/step - loss: 0.0789 - acc: 0.9770 - val_loss: 0.0723 - val_acc: 0.9788\n",
      "Epoch 136/150\n",
      "14319/14319 [==============================] - 3s 215us/step - loss: 0.0786 - acc: 0.9772 - val_loss: 0.0716 - val_acc: 0.9785\n",
      "Epoch 137/150\n",
      "14319/14319 [==============================] - 3s 231us/step - loss: 0.0781 - acc: 0.9777 - val_loss: 0.0796 - val_acc: 0.9768\n",
      "Epoch 138/150\n",
      "14319/14319 [==============================] - 3s 225us/step - loss: 0.0792 - acc: 0.9760 - val_loss: 0.0712 - val_acc: 0.9790\n",
      "Epoch 139/150\n",
      "14319/14319 [==============================] - 3s 231us/step - loss: 0.0783 - acc: 0.9768 - val_loss: 0.0711 - val_acc: 0.9793\n",
      "Epoch 140/150\n",
      "14319/14319 [==============================] - 3s 218us/step - loss: 0.0798 - acc: 0.9765 - val_loss: 0.0724 - val_acc: 0.9785\n",
      "Epoch 141/150\n",
      "14319/14319 [==============================] - 3s 213us/step - loss: 0.0777 - acc: 0.9769 - val_loss: 0.0794 - val_acc: 0.9768\n",
      "Epoch 142/150\n",
      "14319/14319 [==============================] - 3s 220us/step - loss: 0.0798 - acc: 0.9767 - val_loss: 0.0723 - val_acc: 0.9788\n",
      "Epoch 143/150\n",
      "14319/14319 [==============================] - 3s 209us/step - loss: 0.0778 - acc: 0.9774 - val_loss: 0.0729 - val_acc: 0.9788\n",
      "Epoch 144/150\n",
      "14319/14319 [==============================] - 3s 210us/step - loss: 0.0776 - acc: 0.9769 - val_loss: 0.0738 - val_acc: 0.9788\n",
      "Epoch 145/150\n",
      "14319/14319 [==============================] - 3s 207us/step - loss: 0.0782 - acc: 0.9768 - val_loss: 0.0751 - val_acc: 0.9785\n",
      "Epoch 146/150\n",
      "14319/14319 [==============================] - 3s 219us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0717 - val_acc: 0.9782\n",
      "Epoch 147/150\n",
      "14319/14319 [==============================] - 3s 212us/step - loss: 0.0776 - acc: 0.9779 - val_loss: 0.0727 - val_acc: 0.9788\n",
      "Epoch 148/150\n",
      "14319/14319 [==============================] - 3s 200us/step - loss: 0.0784 - acc: 0.9767 - val_loss: 0.0723 - val_acc: 0.9785\n",
      "Epoch 149/150\n",
      "14319/14319 [==============================] - ETA: 0s - loss: 0.0784 - acc: 0.976 - 3s 205us/step - loss: 0.0783 - acc: 0.9768 - val_loss: 0.0735 - val_acc: 0.9799\n",
      "Epoch 150/150\n",
      "14319/14319 [==============================] - 3s 214us/step - loss: 0.0775 - acc: 0.9770 - val_loss: 0.0715 - val_acc: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1175b3588>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Model\n",
    "model.fit(X_train, Y_train, epochs=150, batch_size=15, validation_data=[X_test, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      3259\n",
      "        1.0       0.94      0.81      0.87       320\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Classification metrics on test data\n",
    "predictions = model.predict(X_test)\n",
    "Y_test_predictions = [int(y + 0.5) for y in predictions]\n",
    "print(classification_report(Y_test, Y_test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3579/3579 [==============================] - 0s 30us/step\n",
      "Accuracy: 97.8485610389\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy:\", scores[1] * 100)\n",
    "\n",
    "save_model(model, 'pulsar_CNN_', scores[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "oversampled_positive_examples = []\n",
    "undersampled_negative_exampled = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    # oversampled positive examples\n",
    "    if Y_train[i] == 1 and random() > 0.2:\n",
    "        oversampled_positive_examples.append(i)\n",
    "        \n",
    "    # negative exampled that remain in train dataset (undersampled)\n",
    "    elif Y_train[i] == 0 and random() > 0.4:\n",
    "        undersampled_negative_exampled.append(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampled = X_train[undersampled_negative_exampled]\n",
    "Y_undersampled = Y_train[undersampled_negative_exampled]\n",
    "\n",
    "X_over_under = np.concatenate((X_undersampled, [X_train[i] for i in oversampled_positive_examples]))\n",
    "Y_over_under = np.concatenate((Y_undersampled, [Y_train[i] for i in oversampled_positive_examples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8835 samples, validate on 3579 samples\n",
      "Epoch 1/250\n",
      "8835/8835 [==============================] - 1s 121us/step - loss: 0.0868 - acc: 0.9742 - val_loss: 0.0716 - val_acc: 0.9796\n",
      "Epoch 2/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0856 - acc: 0.9736 - val_loss: 0.0706 - val_acc: 0.9793\n",
      "Epoch 3/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0869 - acc: 0.9746 - val_loss: 0.0777 - val_acc: 0.9776\n",
      "Epoch 4/250\n",
      "8835/8835 [==============================] - 1s 130us/step - loss: 0.0855 - acc: 0.9746 - val_loss: 0.0741 - val_acc: 0.9788\n",
      "Epoch 5/250\n",
      "8835/8835 [==============================] - 1s 137us/step - loss: 0.0874 - acc: 0.9751 - val_loss: 0.0740 - val_acc: 0.9793\n",
      "Epoch 6/250\n",
      "8835/8835 [==============================] - 1s 138us/step - loss: 0.0873 - acc: 0.9746 - val_loss: 0.0712 - val_acc: 0.9793\n",
      "Epoch 7/250\n",
      "8835/8835 [==============================] - 1s 143us/step - loss: 0.0871 - acc: 0.9734 - val_loss: 0.0709 - val_acc: 0.9788\n",
      "Epoch 8/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0863 - acc: 0.9757 - val_loss: 0.0706 - val_acc: 0.9790\n",
      "Epoch 9/250\n",
      "8835/8835 [==============================] - 1s 157us/step - loss: 0.0861 - acc: 0.9732 - val_loss: 0.0722 - val_acc: 0.9790\n",
      "Epoch 10/250\n",
      "8835/8835 [==============================] - 1s 154us/step - loss: 0.0878 - acc: 0.9741 - val_loss: 0.0713 - val_acc: 0.9785\n",
      "Epoch 11/250\n",
      "8835/8835 [==============================] - 1s 136us/step - loss: 0.0843 - acc: 0.9759 - val_loss: 0.0740 - val_acc: 0.9779\n",
      "Epoch 12/250\n",
      "8835/8835 [==============================] - 1s 161us/step - loss: 0.0871 - acc: 0.9740 - val_loss: 0.0721 - val_acc: 0.9788\n",
      "Epoch 13/250\n",
      "8835/8835 [==============================] - 1s 124us/step - loss: 0.0855 - acc: 0.9750 - val_loss: 0.0698 - val_acc: 0.9790\n",
      "Epoch 14/250\n",
      "8835/8835 [==============================] - 1s 121us/step - loss: 0.0845 - acc: 0.9735 - val_loss: 0.0708 - val_acc: 0.9793\n",
      "Epoch 15/250\n",
      "8835/8835 [==============================] - 1s 118us/step - loss: 0.0859 - acc: 0.9751 - val_loss: 0.0716 - val_acc: 0.9788\n",
      "Epoch 16/250\n",
      "8835/8835 [==============================] - 1s 121us/step - loss: 0.0867 - acc: 0.9745 - val_loss: 0.0806 - val_acc: 0.9779\n",
      "Epoch 17/250\n",
      "8835/8835 [==============================] - 1s 118us/step - loss: 0.0864 - acc: 0.9739 - val_loss: 0.0708 - val_acc: 0.9788\n",
      "Epoch 18/250\n",
      "8835/8835 [==============================] - 1s 120us/step - loss: 0.0866 - acc: 0.9760 - val_loss: 0.0733 - val_acc: 0.9782\n",
      "Epoch 19/250\n",
      "8835/8835 [==============================] - 1s 120us/step - loss: 0.0867 - acc: 0.9746 - val_loss: 0.0719 - val_acc: 0.9793\n",
      "Epoch 20/250\n",
      "8835/8835 [==============================] - 1s 117us/step - loss: 0.0881 - acc: 0.9725 - val_loss: 0.0724 - val_acc: 0.9796\n",
      "Epoch 21/250\n",
      "8835/8835 [==============================] - 1s 121us/step - loss: 0.0869 - acc: 0.9743 - val_loss: 0.0715 - val_acc: 0.9788\n",
      "Epoch 22/250\n",
      "8835/8835 [==============================] - 1s 122us/step - loss: 0.0862 - acc: 0.9735 - val_loss: 0.0721 - val_acc: 0.9788\n",
      "Epoch 23/250\n",
      "8835/8835 [==============================] - 1s 126us/step - loss: 0.0856 - acc: 0.9749 - val_loss: 0.0715 - val_acc: 0.9793\n",
      "Epoch 24/250\n",
      "8835/8835 [==============================] - 1s 127us/step - loss: 0.0852 - acc: 0.9749 - val_loss: 0.0711 - val_acc: 0.9790\n",
      "Epoch 25/250\n",
      "8835/8835 [==============================] - 1s 122us/step - loss: 0.0850 - acc: 0.9746 - val_loss: 0.0732 - val_acc: 0.9788\n",
      "Epoch 26/250\n",
      "8835/8835 [==============================] - 1s 121us/step - loss: 0.0845 - acc: 0.9752 - val_loss: 0.0720 - val_acc: 0.9799\n",
      "Epoch 27/250\n",
      "8835/8835 [==============================] - 1s 117us/step - loss: 0.0844 - acc: 0.9744 - val_loss: 0.0722 - val_acc: 0.9782\n",
      "Epoch 28/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0871 - acc: 0.9752 - val_loss: 0.0704 - val_acc: 0.9793\n",
      "Epoch 29/250\n",
      "8835/8835 [==============================] - 1s 121us/step - loss: 0.0871 - acc: 0.9752 - val_loss: 0.0700 - val_acc: 0.9802\n",
      "Epoch 30/250\n",
      "8835/8835 [==============================] - 1s 120us/step - loss: 0.0838 - acc: 0.9752 - val_loss: 0.0715 - val_acc: 0.9796\n",
      "Epoch 31/250\n",
      "8835/8835 [==============================] - 1s 122us/step - loss: 0.0854 - acc: 0.9746 - val_loss: 0.0709 - val_acc: 0.9788\n",
      "Epoch 32/250\n",
      "8835/8835 [==============================] - 1s 122us/step - loss: 0.0850 - acc: 0.9740 - val_loss: 0.0847 - val_acc: 0.9765\n",
      "Epoch 33/250\n",
      "8835/8835 [==============================] - 1s 121us/step - loss: 0.0850 - acc: 0.9746 - val_loss: 0.0745 - val_acc: 0.9793\n",
      "Epoch 34/250\n",
      "8835/8835 [==============================] - 1s 120us/step - loss: 0.0835 - acc: 0.9741 - val_loss: 0.0783 - val_acc: 0.9782\n",
      "Epoch 35/250\n",
      "8835/8835 [==============================] - 1s 120us/step - loss: 0.0861 - acc: 0.9740 - val_loss: 0.0726 - val_acc: 0.9796\n",
      "Epoch 36/250\n",
      "8835/8835 [==============================] - 1s 123us/step - loss: 0.0851 - acc: 0.9741 - val_loss: 0.0731 - val_acc: 0.9790\n",
      "Epoch 37/250\n",
      "8835/8835 [==============================] - 1s 119us/step - loss: 0.0867 - acc: 0.9745 - val_loss: 0.0726 - val_acc: 0.9788\n",
      "Epoch 38/250\n",
      "8835/8835 [==============================] - 1s 118us/step - loss: 0.0861 - acc: 0.9740 - val_loss: 0.0731 - val_acc: 0.9790\n",
      "Epoch 39/250\n",
      "8835/8835 [==============================] - 1s 119us/step - loss: 0.0860 - acc: 0.9754 - val_loss: 0.0716 - val_acc: 0.9790\n",
      "Epoch 40/250\n",
      "8835/8835 [==============================] - 1s 119us/step - loss: 0.0866 - acc: 0.9739 - val_loss: 0.0707 - val_acc: 0.9793\n",
      "Epoch 41/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0855 - acc: 0.9757 - val_loss: 0.0707 - val_acc: 0.9793\n",
      "Epoch 42/250\n",
      "8835/8835 [==============================] - 1s 117us/step - loss: 0.0855 - acc: 0.9763 - val_loss: 0.0712 - val_acc: 0.9804\n",
      "Epoch 43/250\n",
      "8835/8835 [==============================] - 1s 120us/step - loss: 0.0842 - acc: 0.9753 - val_loss: 0.0699 - val_acc: 0.9793\n",
      "Epoch 44/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0860 - acc: 0.9749 - val_loss: 0.0717 - val_acc: 0.9782\n",
      "Epoch 45/250\n",
      "8835/8835 [==============================] - 1s 119us/step - loss: 0.0861 - acc: 0.9743 - val_loss: 0.0735 - val_acc: 0.9810\n",
      "Epoch 46/250\n",
      "8835/8835 [==============================] - 1s 118us/step - loss: 0.0862 - acc: 0.9739 - val_loss: 0.0722 - val_acc: 0.9785\n",
      "Epoch 47/250\n",
      "8835/8835 [==============================] - 1s 120us/step - loss: 0.0851 - acc: 0.9734 - val_loss: 0.0721 - val_acc: 0.9785\n",
      "Epoch 48/250\n",
      "8835/8835 [==============================] - 1s 118us/step - loss: 0.0861 - acc: 0.9746 - val_loss: 0.0721 - val_acc: 0.9782\n",
      "Epoch 49/250\n",
      "8835/8835 [==============================] - 1s 118us/step - loss: 0.0852 - acc: 0.9743 - val_loss: 0.0752 - val_acc: 0.9788\n",
      "Epoch 50/250\n",
      "8835/8835 [==============================] - 1s 119us/step - loss: 0.0856 - acc: 0.9753 - val_loss: 0.0715 - val_acc: 0.9785\n",
      "Epoch 51/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0861 - acc: 0.9729 - val_loss: 0.0710 - val_acc: 0.9793\n",
      "Epoch 52/250\n",
      "8835/8835 [==============================] - 1s 119us/step - loss: 0.0873 - acc: 0.9743 - val_loss: 0.0712 - val_acc: 0.9785\n",
      "Epoch 53/250\n",
      "8835/8835 [==============================] - 1s 117us/step - loss: 0.0849 - acc: 0.9751 - val_loss: 0.0717 - val_acc: 0.9785\n",
      "Epoch 54/250\n",
      "8835/8835 [==============================] - 1s 119us/step - loss: 0.0856 - acc: 0.9752 - val_loss: 0.0716 - val_acc: 0.9788\n",
      "Epoch 55/250\n",
      "8835/8835 [==============================] - 1s 119us/step - loss: 0.0859 - acc: 0.9751 - val_loss: 0.0719 - val_acc: 0.9782\n",
      "Epoch 56/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0851 - acc: 0.9746 - val_loss: 0.0717 - val_acc: 0.9785\n",
      "Epoch 57/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0858 - acc: 0.9744 - val_loss: 0.0712 - val_acc: 0.9785\n",
      "Epoch 58/250\n",
      "8835/8835 [==============================] - 1s 120us/step - loss: 0.0857 - acc: 0.9762 - val_loss: 0.0731 - val_acc: 0.9779\n",
      "Epoch 59/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0869 - acc: 0.9745 - val_loss: 0.0702 - val_acc: 0.9799\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0842 - acc: 0.9752 - val_loss: 0.0715 - val_acc: 0.9788\n",
      "Epoch 61/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0841 - acc: 0.9758 - val_loss: 0.0718 - val_acc: 0.9782\n",
      "Epoch 62/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0848 - acc: 0.9754 - val_loss: 0.0717 - val_acc: 0.9790\n",
      "Epoch 63/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0862 - acc: 0.9745 - val_loss: 0.0724 - val_acc: 0.9785\n",
      "Epoch 64/250\n",
      "8835/8835 [==============================] - 1s 117us/step - loss: 0.0876 - acc: 0.9737 - val_loss: 0.0747 - val_acc: 0.9788\n",
      "Epoch 65/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0860 - acc: 0.9745 - val_loss: 0.0716 - val_acc: 0.9796\n",
      "Epoch 66/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0843 - acc: 0.9745 - val_loss: 0.0731 - val_acc: 0.9779\n",
      "Epoch 67/250\n",
      "8835/8835 [==============================] - 1s 118us/step - loss: 0.0824 - acc: 0.9763 - val_loss: 0.0811 - val_acc: 0.9785\n",
      "Epoch 68/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0845 - acc: 0.9750 - val_loss: 0.0737 - val_acc: 0.9782\n",
      "Epoch 69/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0873 - acc: 0.9746 - val_loss: 0.0714 - val_acc: 0.9788\n",
      "Epoch 70/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0854 - acc: 0.9752 - val_loss: 0.0722 - val_acc: 0.9804\n",
      "Epoch 71/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0845 - acc: 0.9749 - val_loss: 0.0713 - val_acc: 0.9788\n",
      "Epoch 72/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0871 - acc: 0.9731 - val_loss: 0.0717 - val_acc: 0.9802\n",
      "Epoch 73/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0856 - acc: 0.9745 - val_loss: 0.0729 - val_acc: 0.9790\n",
      "Epoch 74/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0863 - acc: 0.9748 - val_loss: 0.0757 - val_acc: 0.9785\n",
      "Epoch 75/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0857 - acc: 0.9745 - val_loss: 0.0723 - val_acc: 0.9790\n",
      "Epoch 76/250\n",
      "8835/8835 [==============================] - 1s 121us/step - loss: 0.0876 - acc: 0.9750 - val_loss: 0.0722 - val_acc: 0.9790\n",
      "Epoch 77/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0842 - acc: 0.9741 - val_loss: 0.0758 - val_acc: 0.9782\n",
      "Epoch 78/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0856 - acc: 0.9753 - val_loss: 0.0789 - val_acc: 0.9796\n",
      "Epoch 79/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0847 - acc: 0.9729 - val_loss: 0.0740 - val_acc: 0.9779\n",
      "Epoch 80/250\n",
      "8835/8835 [==============================] - 1s 119us/step - loss: 0.0839 - acc: 0.9753 - val_loss: 0.0718 - val_acc: 0.9796\n",
      "Epoch 81/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0846 - acc: 0.9734 - val_loss: 0.0752 - val_acc: 0.9776\n",
      "Epoch 82/250\n",
      "8835/8835 [==============================] - 1s 117us/step - loss: 0.0842 - acc: 0.9746 - val_loss: 0.0710 - val_acc: 0.9799\n",
      "Epoch 83/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0872 - acc: 0.9746 - val_loss: 0.0721 - val_acc: 0.9793\n",
      "Epoch 84/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0859 - acc: 0.9741 - val_loss: 0.0756 - val_acc: 0.9790\n",
      "Epoch 85/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0861 - acc: 0.9740 - val_loss: 0.0709 - val_acc: 0.9804\n",
      "Epoch 86/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0864 - acc: 0.9736 - val_loss: 0.0726 - val_acc: 0.9782\n",
      "Epoch 87/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0869 - acc: 0.9749 - val_loss: 0.0713 - val_acc: 0.9790\n",
      "Epoch 88/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0846 - acc: 0.9753 - val_loss: 0.0743 - val_acc: 0.9790\n",
      "Epoch 89/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0854 - acc: 0.9743 - val_loss: 0.0724 - val_acc: 0.9807\n",
      "Epoch 90/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0860 - acc: 0.9743 - val_loss: 0.0732 - val_acc: 0.9776\n",
      "Epoch 91/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0873 - acc: 0.9759 - val_loss: 0.0726 - val_acc: 0.9793\n",
      "Epoch 92/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0843 - acc: 0.9751 - val_loss: 0.0751 - val_acc: 0.9779\n",
      "Epoch 93/250\n",
      "8835/8835 [==============================] - 1s 108us/step - loss: 0.0866 - acc: 0.9750 - val_loss: 0.0723 - val_acc: 0.9779\n",
      "Epoch 94/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0868 - acc: 0.9750 - val_loss: 0.0730 - val_acc: 0.9782\n",
      "Epoch 95/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0839 - acc: 0.9758 - val_loss: 0.0777 - val_acc: 0.9785\n",
      "Epoch 96/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0865 - acc: 0.9734 - val_loss: 0.0719 - val_acc: 0.9790\n",
      "Epoch 97/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0846 - acc: 0.9741 - val_loss: 0.0714 - val_acc: 0.9788\n",
      "Epoch 98/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0853 - acc: 0.9739 - val_loss: 0.0731 - val_acc: 0.9790\n",
      "Epoch 99/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0855 - acc: 0.9750 - val_loss: 0.0742 - val_acc: 0.9779\n",
      "Epoch 100/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0853 - acc: 0.9756 - val_loss: 0.0733 - val_acc: 0.9790\n",
      "Epoch 101/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0878 - acc: 0.9745 - val_loss: 0.0708 - val_acc: 0.9796\n",
      "Epoch 102/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0838 - acc: 0.9737 - val_loss: 0.0724 - val_acc: 0.9802\n",
      "Epoch 103/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0861 - acc: 0.9742 - val_loss: 0.0722 - val_acc: 0.9782\n",
      "Epoch 104/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0855 - acc: 0.9727 - val_loss: 0.0706 - val_acc: 0.9790\n",
      "Epoch 105/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0873 - acc: 0.9737 - val_loss: 0.0722 - val_acc: 0.9779\n",
      "Epoch 106/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0855 - acc: 0.9752 - val_loss: 0.0714 - val_acc: 0.9796\n",
      "Epoch 107/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0853 - acc: 0.9751 - val_loss: 0.0715 - val_acc: 0.9782\n",
      "Epoch 108/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0855 - acc: 0.9746 - val_loss: 0.0755 - val_acc: 0.9779\n",
      "Epoch 109/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0838 - acc: 0.9743 - val_loss: 0.0712 - val_acc: 0.9793\n",
      "Epoch 110/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0858 - acc: 0.9734 - val_loss: 0.0721 - val_acc: 0.9793\n",
      "Epoch 111/250\n",
      "8835/8835 [==============================] - 1s 109us/step - loss: 0.0858 - acc: 0.9736 - val_loss: 0.0722 - val_acc: 0.9796\n",
      "Epoch 112/250\n",
      "8835/8835 [==============================] - 1s 118us/step - loss: 0.0860 - acc: 0.9751 - val_loss: 0.0710 - val_acc: 0.9782\n",
      "Epoch 113/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0860 - acc: 0.9749 - val_loss: 0.0710 - val_acc: 0.9796\n",
      "Epoch 114/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0875 - acc: 0.9749 - val_loss: 0.0709 - val_acc: 0.9788\n",
      "Epoch 115/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0843 - acc: 0.9750 - val_loss: 0.0716 - val_acc: 0.9790\n",
      "Epoch 116/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0855 - acc: 0.9737 - val_loss: 0.0722 - val_acc: 0.9790\n",
      "Epoch 117/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0862 - acc: 0.9750 - val_loss: 0.0743 - val_acc: 0.9799\n",
      "Epoch 118/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0862 - acc: 0.9742 - val_loss: 0.0719 - val_acc: 0.9790\n",
      "Epoch 119/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0833 - acc: 0.9744 - val_loss: 0.0712 - val_acc: 0.9790\n",
      "Epoch 120/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0869 - acc: 0.9735 - val_loss: 0.0714 - val_acc: 0.9788\n",
      "Epoch 121/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0853 - acc: 0.9735 - val_loss: 0.0753 - val_acc: 0.9790\n",
      "Epoch 122/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0837 - acc: 0.9741 - val_loss: 0.0732 - val_acc: 0.9785\n",
      "Epoch 123/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0851 - acc: 0.9750 - val_loss: 0.0724 - val_acc: 0.9790\n",
      "Epoch 124/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0855 - acc: 0.9739 - val_loss: 0.0721 - val_acc: 0.9785\n",
      "Epoch 125/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0861 - acc: 0.9742 - val_loss: 0.0732 - val_acc: 0.9782\n",
      "Epoch 126/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0840 - acc: 0.9743 - val_loss: 0.0716 - val_acc: 0.9790\n",
      "Epoch 127/250\n",
      "8835/8835 [==============================] - 1s 117us/step - loss: 0.0841 - acc: 0.9751 - val_loss: 0.0720 - val_acc: 0.9790\n",
      "Epoch 128/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0854 - acc: 0.9748 - val_loss: 0.0707 - val_acc: 0.9785\n",
      "Epoch 129/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0846 - acc: 0.9743 - val_loss: 0.0723 - val_acc: 0.9793\n",
      "Epoch 130/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0838 - acc: 0.9754 - val_loss: 0.0725 - val_acc: 0.9793\n",
      "Epoch 131/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0865 - acc: 0.9749 - val_loss: 0.0717 - val_acc: 0.9793\n",
      "Epoch 132/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0855 - acc: 0.9749 - val_loss: 0.0723 - val_acc: 0.9788\n",
      "Epoch 133/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0855 - acc: 0.9751 - val_loss: 0.0755 - val_acc: 0.9790\n",
      "Epoch 134/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0844 - acc: 0.9750 - val_loss: 0.0718 - val_acc: 0.9790\n",
      "Epoch 135/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0842 - acc: 0.9746 - val_loss: 0.0728 - val_acc: 0.9790\n",
      "Epoch 136/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0863 - acc: 0.9743 - val_loss: 0.0707 - val_acc: 0.9804\n",
      "Epoch 137/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0870 - acc: 0.9748 - val_loss: 0.0717 - val_acc: 0.9788\n",
      "Epoch 138/250\n",
      "8835/8835 [==============================] - 1s 109us/step - loss: 0.0832 - acc: 0.9751 - val_loss: 0.0717 - val_acc: 0.9802\n",
      "Epoch 139/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0859 - acc: 0.9740 - val_loss: 0.0744 - val_acc: 0.9782\n",
      "Epoch 140/250\n",
      "8835/8835 [==============================] - 1s 120us/step - loss: 0.0849 - acc: 0.9745 - val_loss: 0.0708 - val_acc: 0.9793\n",
      "Epoch 141/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0852 - acc: 0.9754 - val_loss: 0.0731 - val_acc: 0.9788\n",
      "Epoch 142/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0854 - acc: 0.9749 - val_loss: 0.0733 - val_acc: 0.9802\n",
      "Epoch 143/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0840 - acc: 0.9750 - val_loss: 0.0736 - val_acc: 0.9782\n",
      "Epoch 144/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0853 - acc: 0.9743 - val_loss: 0.0715 - val_acc: 0.9779\n",
      "Epoch 145/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0867 - acc: 0.9736 - val_loss: 0.0740 - val_acc: 0.9802\n",
      "Epoch 146/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0859 - acc: 0.9749 - val_loss: 0.0766 - val_acc: 0.9776\n",
      "Epoch 147/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0848 - acc: 0.9752 - val_loss: 0.0712 - val_acc: 0.9790\n",
      "Epoch 148/250\n",
      "8835/8835 [==============================] - 1s 107us/step - loss: 0.0850 - acc: 0.9756 - val_loss: 0.0704 - val_acc: 0.9799\n",
      "Epoch 149/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0854 - acc: 0.9746 - val_loss: 0.0712 - val_acc: 0.9802\n",
      "Epoch 150/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0837 - acc: 0.9734 - val_loss: 0.0727 - val_acc: 0.9785\n",
      "Epoch 151/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0872 - acc: 0.9740 - val_loss: 0.0739 - val_acc: 0.9796\n",
      "Epoch 152/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0869 - acc: 0.9734 - val_loss: 0.0711 - val_acc: 0.9793\n",
      "Epoch 153/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0855 - acc: 0.9741 - val_loss: 0.0724 - val_acc: 0.9790\n",
      "Epoch 154/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0850 - acc: 0.9754 - val_loss: 0.0714 - val_acc: 0.9788\n",
      "Epoch 155/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0860 - acc: 0.9751 - val_loss: 0.0718 - val_acc: 0.9788\n",
      "Epoch 156/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0837 - acc: 0.9744 - val_loss: 0.0725 - val_acc: 0.9785\n",
      "Epoch 157/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0874 - acc: 0.9745 - val_loss: 0.0720 - val_acc: 0.9799\n",
      "Epoch 158/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0851 - acc: 0.9756 - val_loss: 0.0719 - val_acc: 0.9779\n",
      "Epoch 159/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0859 - acc: 0.9740 - val_loss: 0.0742 - val_acc: 0.9788\n",
      "Epoch 160/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0863 - acc: 0.9745 - val_loss: 0.0711 - val_acc: 0.9788\n",
      "Epoch 161/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0838 - acc: 0.9751 - val_loss: 0.0760 - val_acc: 0.9796\n",
      "Epoch 162/250\n",
      "8835/8835 [==============================] - 1s 109us/step - loss: 0.0857 - acc: 0.9766 - val_loss: 0.0750 - val_acc: 0.9790\n",
      "Epoch 163/250\n",
      "8835/8835 [==============================] - 1s 109us/step - loss: 0.0845 - acc: 0.9744 - val_loss: 0.0730 - val_acc: 0.9788\n",
      "Epoch 164/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0844 - acc: 0.9753 - val_loss: 0.0770 - val_acc: 0.9785\n",
      "Epoch 165/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0853 - acc: 0.9761 - val_loss: 0.0730 - val_acc: 0.9793\n",
      "Epoch 166/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0871 - acc: 0.9740 - val_loss: 0.0736 - val_acc: 0.9788\n",
      "Epoch 167/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0849 - acc: 0.9745 - val_loss: 0.0727 - val_acc: 0.9790\n",
      "Epoch 168/250\n",
      "8835/8835 [==============================] - 1s 108us/step - loss: 0.0864 - acc: 0.9748 - val_loss: 0.0738 - val_acc: 0.9782\n",
      "Epoch 169/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0845 - acc: 0.9742 - val_loss: 0.0708 - val_acc: 0.9785\n",
      "Epoch 170/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0867 - acc: 0.9749 - val_loss: 0.0710 - val_acc: 0.9788\n",
      "Epoch 171/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0863 - acc: 0.9742 - val_loss: 0.0717 - val_acc: 0.9804\n",
      "Epoch 172/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0830 - acc: 0.9746 - val_loss: 0.0722 - val_acc: 0.9790\n",
      "Epoch 173/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0822 - acc: 0.9748 - val_loss: 0.0704 - val_acc: 0.9785\n",
      "Epoch 174/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0857 - acc: 0.9748 - val_loss: 0.0719 - val_acc: 0.9804\n",
      "Epoch 175/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0835 - acc: 0.9759 - val_loss: 0.0743 - val_acc: 0.9790\n",
      "Epoch 176/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0840 - acc: 0.9750 - val_loss: 0.0721 - val_acc: 0.9788\n",
      "Epoch 177/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0856 - acc: 0.9748 - val_loss: 0.0716 - val_acc: 0.9796\n",
      "Epoch 178/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0842 - acc: 0.9746 - val_loss: 0.0776 - val_acc: 0.9793\n",
      "Epoch 179/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0830 - acc: 0.9746 - val_loss: 0.0738 - val_acc: 0.9793\n",
      "Epoch 180/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0847 - acc: 0.9766 - val_loss: 0.0711 - val_acc: 0.9793\n",
      "Epoch 181/250\n",
      "8835/8835 [==============================] - 1s 118us/step - loss: 0.0853 - acc: 0.9737 - val_loss: 0.0739 - val_acc: 0.9790\n",
      "Epoch 182/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0851 - acc: 0.9746 - val_loss: 0.0706 - val_acc: 0.9799\n",
      "Epoch 183/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0857 - acc: 0.9742 - val_loss: 0.0725 - val_acc: 0.9790\n",
      "Epoch 184/250\n",
      "8835/8835 [==============================] - 1s 110us/step - loss: 0.0855 - acc: 0.9737 - val_loss: 0.0735 - val_acc: 0.9782\n",
      "Epoch 185/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0836 - acc: 0.9749 - val_loss: 0.0708 - val_acc: 0.9790\n",
      "Epoch 186/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0869 - acc: 0.9744 - val_loss: 0.0723 - val_acc: 0.9793\n",
      "Epoch 187/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0855 - acc: 0.9735 - val_loss: 0.0704 - val_acc: 0.9788\n",
      "Epoch 188/250\n",
      "8835/8835 [==============================] - 1s 117us/step - loss: 0.0851 - acc: 0.9746 - val_loss: 0.0738 - val_acc: 0.9790\n",
      "Epoch 189/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0858 - acc: 0.9745 - val_loss: 0.0717 - val_acc: 0.9804\n",
      "Epoch 190/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0839 - acc: 0.9741 - val_loss: 0.0711 - val_acc: 0.9796\n",
      "Epoch 191/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0827 - acc: 0.9735 - val_loss: 0.0718 - val_acc: 0.9788\n",
      "Epoch 192/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0852 - acc: 0.9746 - val_loss: 0.0711 - val_acc: 0.9788\n",
      "Epoch 193/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0835 - acc: 0.9753 - val_loss: 0.0710 - val_acc: 0.9804\n",
      "Epoch 194/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0847 - acc: 0.9759 - val_loss: 0.0734 - val_acc: 0.9799\n",
      "Epoch 195/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0849 - acc: 0.9736 - val_loss: 0.0723 - val_acc: 0.9793\n",
      "Epoch 196/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0856 - acc: 0.9739 - val_loss: 0.0725 - val_acc: 0.9774\n",
      "Epoch 197/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0842 - acc: 0.9742 - val_loss: 0.0710 - val_acc: 0.9788\n",
      "Epoch 198/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0852 - acc: 0.9750 - val_loss: 0.0718 - val_acc: 0.9785\n",
      "Epoch 199/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0833 - acc: 0.9765 - val_loss: 0.0718 - val_acc: 0.9802\n",
      "Epoch 200/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0840 - acc: 0.9742 - val_loss: 0.0722 - val_acc: 0.9788\n",
      "Epoch 201/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0856 - acc: 0.9741 - val_loss: 0.0711 - val_acc: 0.9785\n",
      "Epoch 202/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0850 - acc: 0.9749 - val_loss: 0.0764 - val_acc: 0.9799\n",
      "Epoch 203/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0851 - acc: 0.9748 - val_loss: 0.0709 - val_acc: 0.9790\n",
      "Epoch 204/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0846 - acc: 0.9749 - val_loss: 0.0714 - val_acc: 0.9782\n",
      "Epoch 205/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0854 - acc: 0.9748 - val_loss: 0.0714 - val_acc: 0.9796\n",
      "Epoch 206/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0845 - acc: 0.9750 - val_loss: 0.0710 - val_acc: 0.9793\n",
      "Epoch 207/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0833 - acc: 0.9753 - val_loss: 0.0713 - val_acc: 0.9774\n",
      "Epoch 208/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0847 - acc: 0.9745 - val_loss: 0.0735 - val_acc: 0.9796\n",
      "Epoch 209/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0843 - acc: 0.9744 - val_loss: 0.0747 - val_acc: 0.9776\n",
      "Epoch 210/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0833 - acc: 0.9758 - val_loss: 0.0798 - val_acc: 0.9790\n",
      "Epoch 211/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0850 - acc: 0.9741 - val_loss: 0.0757 - val_acc: 0.9793\n",
      "Epoch 212/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0850 - acc: 0.9748 - val_loss: 0.0706 - val_acc: 0.9785\n",
      "Epoch 213/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0855 - acc: 0.9742 - val_loss: 0.0715 - val_acc: 0.9782\n",
      "Epoch 214/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0853 - acc: 0.9744 - val_loss: 0.0729 - val_acc: 0.9793\n",
      "Epoch 215/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0861 - acc: 0.9750 - val_loss: 0.0712 - val_acc: 0.9788\n",
      "Epoch 216/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0868 - acc: 0.9748 - val_loss: 0.0712 - val_acc: 0.9804\n",
      "Epoch 217/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0836 - acc: 0.9733 - val_loss: 0.0727 - val_acc: 0.9785\n",
      "Epoch 218/250\n",
      "8835/8835 [==============================] - 1s 117us/step - loss: 0.0830 - acc: 0.9745 - val_loss: 0.0712 - val_acc: 0.9810\n",
      "Epoch 219/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0846 - acc: 0.9742 - val_loss: 0.0705 - val_acc: 0.9790\n",
      "Epoch 220/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0843 - acc: 0.9751 - val_loss: 0.0778 - val_acc: 0.9790\n",
      "Epoch 221/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0855 - acc: 0.9739 - val_loss: 0.0711 - val_acc: 0.9799\n",
      "Epoch 222/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0833 - acc: 0.9760 - val_loss: 0.0726 - val_acc: 0.9793\n",
      "Epoch 223/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0829 - acc: 0.9744 - val_loss: 0.0723 - val_acc: 0.9799\n",
      "Epoch 224/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0847 - acc: 0.9752 - val_loss: 0.0716 - val_acc: 0.9788\n",
      "Epoch 225/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0856 - acc: 0.9754 - val_loss: 0.0724 - val_acc: 0.9790\n",
      "Epoch 226/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0838 - acc: 0.9742 - val_loss: 0.0734 - val_acc: 0.9790\n",
      "Epoch 227/250\n",
      "8835/8835 [==============================] - 1s 110us/step - loss: 0.0816 - acc: 0.9750 - val_loss: 0.0713 - val_acc: 0.9802\n",
      "Epoch 228/250\n",
      "8835/8835 [==============================] - 1s 108us/step - loss: 0.0846 - acc: 0.9740 - val_loss: 0.0730 - val_acc: 0.9785\n",
      "Epoch 229/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0834 - acc: 0.9766 - val_loss: 0.0748 - val_acc: 0.9799\n",
      "Epoch 230/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0846 - acc: 0.9754 - val_loss: 0.0738 - val_acc: 0.9807\n",
      "Epoch 231/250\n",
      "8835/8835 [==============================] - 1s 113us/step - loss: 0.0837 - acc: 0.9739 - val_loss: 0.0718 - val_acc: 0.9790\n",
      "Epoch 232/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0853 - acc: 0.9742 - val_loss: 0.0709 - val_acc: 0.9799\n",
      "Epoch 233/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0852 - acc: 0.9745 - val_loss: 0.0727 - val_acc: 0.9807\n",
      "Epoch 234/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0846 - acc: 0.9751 - val_loss: 0.0710 - val_acc: 0.9796\n",
      "Epoch 235/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0852 - acc: 0.9753 - val_loss: 0.0713 - val_acc: 0.9804\n",
      "Epoch 236/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0849 - acc: 0.9749 - val_loss: 0.0710 - val_acc: 0.9796\n",
      "Epoch 237/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0829 - acc: 0.9752 - val_loss: 0.0753 - val_acc: 0.9779\n",
      "Epoch 238/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0839 - acc: 0.9749 - val_loss: 0.0708 - val_acc: 0.9785\n",
      "Epoch 239/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0826 - acc: 0.9758 - val_loss: 0.0725 - val_acc: 0.9793\n",
      "Epoch 240/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0861 - acc: 0.9750 - val_loss: 0.0729 - val_acc: 0.9790\n",
      "Epoch 241/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0853 - acc: 0.9752 - val_loss: 0.0743 - val_acc: 0.9788\n",
      "Epoch 242/250\n",
      "8835/8835 [==============================] - 1s 111us/step - loss: 0.0850 - acc: 0.9745 - val_loss: 0.0717 - val_acc: 0.9799\n",
      "Epoch 243/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0847 - acc: 0.9745 - val_loss: 0.0730 - val_acc: 0.9796\n",
      "Epoch 244/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0845 - acc: 0.9744 - val_loss: 0.0716 - val_acc: 0.9790\n",
      "Epoch 245/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0845 - acc: 0.9753 - val_loss: 0.0726 - val_acc: 0.9785\n",
      "Epoch 246/250\n",
      "8835/8835 [==============================] - 1s 116us/step - loss: 0.0863 - acc: 0.9742 - val_loss: 0.0699 - val_acc: 0.9785\n",
      "Epoch 247/250\n",
      "8835/8835 [==============================] - 1s 110us/step - loss: 0.0833 - acc: 0.9753 - val_loss: 0.0713 - val_acc: 0.9796\n",
      "Epoch 248/250\n",
      "8835/8835 [==============================] - 1s 114us/step - loss: 0.0840 - acc: 0.9737 - val_loss: 0.0759 - val_acc: 0.9790\n",
      "Epoch 249/250\n",
      "8835/8835 [==============================] - 1s 112us/step - loss: 0.0832 - acc: 0.9753 - val_loss: 0.0734 - val_acc: 0.9799\n",
      "Epoch 250/250\n",
      "8835/8835 [==============================] - 1s 115us/step - loss: 0.0838 - acc: 0.9737 - val_loss: 0.0706 - val_acc: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117f56c18>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One more run on oversampled and undersampled dataset\n",
    "model.fit(X_over_under, Y_over_under, epochs=250, batch_size=30, validation_data=[X_test, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.99      3259\n",
      "        1.0       0.92      0.83      0.87       320\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Classification metrics on test data\n",
    "predictions = model.predict(X_test)\n",
    "Y_test_predictions = [int(y + 0.5) for y in predictions]\n",
    "print(classification_report(Y_test, Y_test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3579/3579 [==============================] - 0s 41us/step\n",
      "Accuracy: 97.8485610389\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy:\", scores[1] * 100)\n",
    "\n",
    "save_model(model, 'pulsar_CNN_', scores[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
