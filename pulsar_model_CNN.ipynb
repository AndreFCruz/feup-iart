{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_PATH = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "\n",
    "def load_pulsar_csv(path = DATA_PATH):\n",
    "    csv_path = os.path.join(path, 'HTRU_2.csv')\n",
    "    return np.loadtxt(csv_path, delimiter=',', dtype=np.float32)\n",
    "\n",
    "def load_pulsar_arff(path = DATA_PATH):\n",
    "    arff_path = os.path.join(path, 'HTRU_2.arff')\n",
    "    return arff.loadarff(arff_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pulsars = load_pulsar_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_train_dataset(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(test_ratio * len(data))\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data[train_indices,:], data[test_indices,:]\n",
    "\n",
    "# Use hash of identifier to decide if instance goes into train or test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "import os\n",
    "\n",
    "MODELS_DIR = \"models\"\n",
    "\n",
    "def save_model(model, name, acc=None):\n",
    "    name += str(model.input.shape[1])\n",
    "    for layer in model.layers:\n",
    "        name += \"-\" + str(layer.output.shape[1])\n",
    "    \n",
    "    name += \"_\" + ((\"%.2f\" % acc) if acc is not None else \"\")\n",
    "    path = os.path.join(MODELS_DIR, name + \".h5\")\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = split_train_dataset(pulsars, 0.2)\n",
    "\n",
    "X_train, Y_train = train_set[:, :-1], train_set[:, -1]\n",
    "X_test, Y_test = test_set[:, :-1], test_set[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Dropout, Flatten, Reshape\n",
    "\n",
    "# Create Model\n",
    "input_dimension = np.size(X_train, axis=1)\n",
    "\n",
    "def create_model_cnn():\n",
    "    inputs = Input(shape=(input_dimension,), dtype='float32')\n",
    "    reshape = Reshape((input_dimension,1))(inputs) # reshape input (?,8) to conv input (?,8,1)\n",
    "    conv_0 = Conv1D(64, kernel_size=4, activation='relu')(reshape)\n",
    "    pool = MaxPooling1D()(conv_0)\n",
    "    flatten = Flatten()(pool)\n",
    "    dropout = Dropout(0.2)(flatten)\n",
    "    output = Dense(1, activation='sigmoid')(dropout)\n",
    "    # Compile model\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14319 samples, validate on 3579 samples\n",
      "Epoch 1/150\n",
      "14319/14319 [==============================] - 3s 229us/step - loss: 0.1798 - acc: 0.9589 - val_loss: 0.0949 - val_acc: 0.9754\n",
      "Epoch 2/150\n",
      "10200/14319 [====================>.........] - ETA: 0s - loss: 0.1090 - acc: 0.9702"
     ]
    }
   ],
   "source": [
    "# Fit the Model\n",
    "model.fit(X_train, Y_train, epochs=150, batch_size=15, validation_data=[X_test, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
